{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a faire\n",
    "* pays de paul \n",
    "    * regarder du coté d'open street map car je pense meilleur truc même si va prendre du temps : https://nominatim.org/release-docs/develop/api/Search/\n",
    "    * extraire la date OK\n",
    "    * nettoyer les place\n",
    "        * enlever le \"The \" au début OK\n",
    "        * enlever les doublons OK\n",
    "        * enlever les doublons comme Gaza et GAZA (on met tout en minuscule) OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "import time\n",
    "\n",
    "current_year = time.strftime(\"%y\", time.localtime())\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.vocab[\"CLASSIFIED\"].is_stop = True # On ajoute CLASSIFIED au stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './echantillon-cablegate_converted/'\n",
    "files = [f for f in listdir(data_path) if f[-4:] == '.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNITED STATES\n",
      "UNITED STATES\n",
      "UNITED STATES\n",
      "CENTRAL HIGHLANDS\n",
      "UNITED STATES\n",
      "UNITED STATES\n",
      "CENTRAL HIGHLANDS\n",
      "WEST BANK/GAZA COUNTRY\n",
      "NETHERLANDS\n"
     ]
    }
   ],
   "source": [
    "# Cleaning\n",
    "res = {}\n",
    "for i in range(0, 4):\n",
    "    with open(data_path + files[i], encoding=\"utf8\", errors='ignore') as f:\n",
    "        content = f.read()\n",
    "\n",
    "        extracted_doc = {}\n",
    "        \n",
    "        extracted_doc['doc_name'] = files[i][:-4]\n",
    "        extracted_doc['date'] = extract_date(content)\n",
    "        extracted_doc['tags'] = extract_tags(content)\n",
    "        extracted_doc['from'] = extract_from(content)\n",
    "        extracted_doc['place_of_document'] = re.findall(r\"[A-Z]+\", extracted_doc['doc_name'])[-1] # -1 because we take the last one\n",
    "        extracted_doc['subject'] = extract_subject(content)\n",
    "        extracted_doc['most_common_words'] = extract_most_common_words(content)\n",
    "        extracted_doc['keywords'] = extract_keywords(content)\n",
    "\n",
    "        ner = dict([(str(x), x.label_) for x in nlp(content).ents])\n",
    "        extracted_doc['people_involved'] = extract_people_involved(ner)\n",
    "        extracted_doc['place_involved'] = extract_place_involved(ner)\n",
    "        extracted_doc['entity_involved'] = extract_entity_involved(ner)\n",
    "\n",
    "\n",
    "        res[i] = extracted_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d4219a38c189>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject(content):\n",
    "    subject_pos = content.index('\\nSUBJECT: ') + len('\\nSUBJECT: ') \n",
    "    subject = content[subject_pos: subject_pos + 500]\n",
    "    subject = subject[:subject.index('\\n \\n')].replace('\\n', ' ')\n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(content):\n",
    "    date_line = re.search(r\"[A-Z]\\s[0-9]{6}[A-Z]\\s[A-Z]{3}\\s[0-9]{2}\", content)\n",
    "    \n",
    "    date_line = date_line.group()\n",
    "    date_month = date_line.split(\" \")[2]\n",
    "    date_year = date_line.split(\" \")[3]\n",
    "    \n",
    "    months = ['JAN', 'FEV', 'MAR', \"APR\", \"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"]\n",
    "    \n",
    "    date = {}\n",
    "    date['year'] = None\n",
    "    date['month'] = None\n",
    "    if date_month in months :\n",
    "        if int(date_year) > int(current_year):\n",
    "            year = \"19\"+date_year\n",
    "        else:\n",
    "            year=\"20\"+date_year\n",
    "        date['year'] = year\n",
    "        date['month'] = date_month\n",
    "    else :\n",
    "        print(\"ERR : unexpected month =\", date_month)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(content):\n",
    "    tags_list = [line for line in content.splitlines() if line.startswith(r\"TAGS:\")]\n",
    "    return tags_list[0].split()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from(content):\n",
    "    #fm_list = [line for line in content.splitlines() if line.startswith(\"FM \")]\n",
    "    #return fm_list[0][3:-1] # y a toujours un espace à la fin\n",
    "    FROM = re.search(r\"\\nFM\\s[A-Z\\s]+\\nTO \", content)\n",
    "    if FROM != None :\n",
    "        FROM = FROM.group()[4:-4]\n",
    "    else:\n",
    "        #print(re.search(r\"\\nFOR\\s[A-Z\\/s]+\", content))\n",
    "        FROM = re.search(r\"\\nFOR\\s[A-Z\\s\\/]+\\n\", content)\n",
    "        if FROM != None :\n",
    "            FROM = FROM.group()[5:-1]\n",
    "            FROM =re.split(', | AND ',FROM)\n",
    "    return FROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_most_common_words(content):\n",
    "    doc = nlp(content)\n",
    "    # all tokens that arent stop words or punctuations\n",
    "    words = [token.text for token in doc if not token.is_stop and not token.is_punct and token.text not in (\"\\n\", \"\\n \\n\", \"\\n \\n \\n\")]\n",
    "\n",
    "    # fiftenth most common tokens\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(15)\n",
    "    return [word for word in common_words if len(word[0])>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] # 1\n",
    "    doc = nlp(text.lower()) # 2\n",
    "    for token in doc:\n",
    "        # 3\n",
    "        if(token.is_stop or token.text in punctuation):\n",
    "            continue\n",
    "        # 4\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "                \n",
    "    return result # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(content):\n",
    "    output = set(get_hotwords(content))\n",
    "    return [x[0] for x in Counter(output).most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity_involved(ner):\n",
    "    entity_involved = [key.replace('\\n', '').replace('   ', ' ').replace('  ',' ') for key in ner.keys() if ner[key] == 'ORG' or ner[key] == 'NORP' ]\n",
    "    res = []\n",
    "    for entity in entity_involved: # to remove duplicates\n",
    "        if entity not in res:\n",
    "            res.append(entity)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_place_involved(ner):\n",
    "    place_involved = [key\n",
    "                      .replace('\\n', '')\n",
    "                      .replace('   ', ' ')\n",
    "                      .replace('  ', ' ')\n",
    "                      .upper()\n",
    "                      for key in ner.keys() if ner[key] == 'GPE' or ner[key] == 'LOC' ]\n",
    "    res = []\n",
    "    for place in place_involved: # to remove duplicates\n",
    "        if place[0:4]==\"THE \" and len(place)>4:\n",
    "                place = place.replace(\"THE \", \"\")\n",
    "                print(place)\n",
    "        if place not in res:\n",
    "            res.append(place)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_people_involved(ner): # on laisse sipdis parce que peut être une personne\n",
    "    people_involved = [key.replace('\\n', '').replace('   ', ' ').replace('  ', ' ') for key in ner.keys() if ner[key] == 'PERSON']\n",
    "    res = []\n",
    "    for people in people_involved: # to remove duplicates\n",
    "        if people not in res:\n",
    "            res.append(people)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {0: {'date': {'month': 'DEC', 'year': '2006'},\n",
    "     'doc_name': '06HONGKONG4795',\n",
    "     'entity_involved': ['RHMFIUU/HQ',\n",
    "                         'USDOC',\n",
    "                         'OEA',\n",
    "                         'LHINES/DFARROW USDOC',\n",
    "                         'FCS',\n",
    "                         'the Export Administration Act',\n",
    "                         'the Office of Enforcement Analysis',\n",
    "                         'the USDOC Bureau of Industry and Security',\n",
    "                         'BIS',\n",
    "                         'Export Control',\n",
    "                         'Advanced Energy-Shenzhen ',\n",
    "                         'Baltrans',\n",
    "                         'ECCN',\n",
    "                         'International Rectifier of Leominster',\n",
    "                         'International Rectifier',\n",
    "                         'Advanced Energy',\n",
    "                         'ECO',\n",
    "                         'Airfreight Operations',\n",
    "                         'Operations Manager',\n",
    "                         'Airfreight',\n",
    "                         'Federal Express',\n",
    "                         \"Advanced Energy's\",\n",
    "                         'BIS '],\n",
    "     'from': 'AMCONSUL HONG KONG',\n",
    "     'keywords': ['subject', 'ankel', 'providers', 'street', 'route'],\n",
    "     'most_common_words': [('Advanced', 14),\n",
    "                           ('Energy', 14),\n",
    "                           ('Baltrans', 10),\n",
    "                           ('Mr.', 10),\n",
    "                           ('Lam', 9),\n",
    "                           ('shipment', 8),\n",
    "                           ('Hong', 8),\n",
    "                           ('Kong', 8),\n",
    "                           ('items', 8),\n",
    "                           ('ECO', 6),\n",
    "                           ('USDOC', 5),\n",
    "                           ('export', 5),\n",
    "                           ('OEA', 4),\n",
    "                           ('provided', 4)],\n",
    "     'people_involved': ['RUCPDOC',\n",
    "                         'RUEHC',\n",
    "                         'SIPDIS ',\n",
    "                         'WILLIAM ZARIT ',\n",
    "                         'BMGT BEXP',\n",
    "                         'ETRD ETTC',\n",
    "                         'Philip Ankel',\n",
    "                         'Tai Yip Street',\n",
    "                         'Theodore Shum',\n",
    "                         'Gordon Lam',\n",
    "                         'Lam',\n",
    "                         'Cunningham'],\n",
    "     'place_involved': ['KOWLOON',\n",
    "                        'HONG KONG',\n",
    "                        'CHINA',\n",
    "                        'MASSACHUSETTS',\n",
    "                        'UNITED STATES',\n",
    "                        'SHENZHEN'],\n",
    "     'place_of_document': 'HONGKONG',\n",
    "     'subject': 'EXTRANCHECK: POST SHIPMENT VERIFICATION:  ADVANCED '\n",
    "                'ENERGY-SHENZHEN C/O BALTRANS LOGISTRIC ',\n",
    "     'tags': ['BMGT', 'BEXP', 'HK', 'ETRD', 'ETTC']},\n",
    " 1: {'date': {'month': 'AUG', 'year': '2006'},\n",
    "     'doc_name': '06HOCHIMINHCITY917',\n",
    "     'entity_involved': ['RUEHC/SECSTATE WASHDC PRIORITY',\n",
    "                         'RUCNARF',\n",
    "                         'RUEHHM/AMCONSUL HO',\n",
    "                         'PHUM PGOV PREF KIRF',\n",
    "                         'Consul General',\n",
    "                         'State',\n",
    "                         'the Montagnard Foundation',\n",
    "                         'ConGen',\n",
    "                         'GVN',\n",
    "                         'Southern Evangelical Church of Vietnam',\n",
    "                         'Dak Nong',\n",
    "                         'SBU',\n",
    "                         'Vietnamese Embassy',\n",
    "                         'PNTR',\n",
    "                         'Congress',\n",
    "                         'WINNICK'],\n",
    "     'from': 'AMCONSUL HO CHI MINH CITY',\n",
    "     'keywords': ['subject', 'migrants', 'congress', 'collective', 'leader'],\n",
    "     'most_common_words': [('police', 12),\n",
    "                           ('ethnic', 7),\n",
    "                           ('minority', 7),\n",
    "                           ('Adrong', 7),\n",
    "                           ('contact', 7),\n",
    "                           ('province', 6),\n",
    "                           ('HCMC', 5),\n",
    "                           ('United', 5),\n",
    "                           ('States', 5),\n",
    "                           ('Central', 5),\n",
    "                           ('Highlands', 5),\n",
    "                           ('SECV', 5),\n",
    "                           ('contacts', 4)],\n",
    "     'people_involved': ['RUEHCHI RUEHDT RUEHNH',\n",
    "                         'HO CHI MINH CITY',\n",
    "                         '000917 ',\n",
    "                         'SIPDIS ',\n",
    "                         'E.O.',\n",
    "                         'DECL',\n",
    "                         'Seth Winnick',\n",
    "                         'Y Ngo Adrong',\n",
    "                         'Adrong',\n",
    "                         'Siu Y Kim',\n",
    "                         'Gia Lai',\n",
    "                         'Chu Se',\n",
    "                         'Kim',\n",
    "                         'Dega',\n",
    "                         'Phu Yen'],\n",
    "     'place_involved': ['CENTRAL HIGHLANDS',\n",
    "                        'HCMC',\n",
    "                        'UNITED STATES',\n",
    "                        'DAK LAK',\n",
    "                        'CAMBODIA',\n",
    "                        'VIETNAM',\n",
    "                        'WASHINGTON'],\n",
    "     'place_of_document': 'HOCHIMINHCITY',\n",
    "     'subject': 'POLICE BRUTALITY RISING; CENTRAL HIGHLANDS DEATH CONFIRMED ',\n",
    "     'tags': ['PHUM', 'PGOV', 'PREF', 'KIRF', 'VM']},\n",
    " 2: {'date': {'month': 'MAR', 'year': '2006'},\n",
    "     'doc_name': '06JERUSALEM906',\n",
    "     'entity_involved': ['RUEHC/SECSTATE WASHDC',\n",
    "                         '0698',\n",
    "                         'RHEHNSC',\n",
    "                         'NSC',\n",
    "                         'RUEHBS/USEU BRUSSELS',\n",
    "                         'FRONT OFFICE',\n",
    "                         'NEA/IPA',\n",
    "                         'WILLIAMS/GREENE/WAECHTER',\n",
    "                         'ABRAMS',\n",
    "                         'PHUM PREF EAID ECON',\n",
    "                         'SBU',\n",
    "                         'the World Food Program',\n",
    "                         'WFP',\n",
    "                         'ECON',\n",
    "                         'the PA Ministry of National Economy',\n",
    "                         'UNRWA',\n",
    "                         'Market Monitoring'],\n",
    "     'from': 'AMCONSUL JERUSALEM',\n",
    "     'keywords': ['subject', 'vulnerability', 'collective', 'works', 'phum'],\n",
    "     'most_common_words': [('days', 11),\n",
    "                           ('food', 7),\n",
    "                           ('IMMEDIATE', 5),\n",
    "                           ('Gaza', 5),\n",
    "                           ('price', 5),\n",
    "                           ('flour', 4),\n",
    "                           ('WASHDC', 3),\n",
    "                           ('WFP', 3),\n",
    "                           ('March', 3),\n",
    "                           ('Karni', 3),\n",
    "                           ('stocks', 3),\n",
    "                           ('report', 3),\n",
    "                           ('percent', 3),\n",
    "                           ('JERUSALEM', 2)],\n",
    "     'people_involved': ['000906 ',\n",
    "                         'SIPDIS ',\n",
    "                         'NEA',\n",
    "                         'DORAN',\n",
    "                         'MUSTAFA ',\n",
    "                         'Arnold Vercken',\n",
    "                         'Karni'],\n",
    "     'place_involved': ['GAZA', 'WEST BANK/GAZA COUNTRY', 'U.S.'],\n",
    "     'place_of_document': 'JERUSALEM',\n",
    "     'subject': 'KARNI CLOSURE CAUSING FOOD SHORTAGE IN GAZA ',\n",
    "     'tags': ['PHUM', 'PREF', 'EAID', 'ECON', 'KWBG']},\n",
    " 3: {'date': {'month': 'JUL', 'year': '2009'},\n",
    "     'doc_name': '09BERLIN831',\n",
    "     'entity_involved': ['RUEHC/SECSTATE WASHDC',\n",
    "                         'RUEHAD',\n",
    "                         'AMEMBASSY ABU DHABI',\n",
    "                         'RUEHUJA',\n",
    "                         'AMEMBASSY ABUJA PRIORITY',\n",
    "                         'RUEHAK',\n",
    "                         'AMEMBASSY ANKARA',\n",
    "                         'RUEHTH',\n",
    "                         'AMEMBASSY ATHENS',\n",
    "                         'RUEHBS/',\n",
    "                         'AMEMBASSY',\n",
    "                         'RUEHEG',\n",
    "                         'AMEMBASSY CAIRO',\n",
    "                         'RUEHBY',\n",
    "                         'AMEMBASSY CANBERRA',\n",
    "                         'RUEHCP',\n",
    "                         'AMEMBASSY COPENHAGEN',\n",
    "                         'RUEHDJ',\n",
    "                         'RUEHKL',\n",
    "                         'AMEMBASSY KUALA LUMPUR',\n",
    "                         'RUEHLI',\n",
    "                         'AMEMBASSY LONDON',\n",
    "                         'RUEHMD',\n",
    "                         'RUEHMV',\n",
    "                         'AMEMBASSY MONROVIA',\n",
    "                         'RUEHMO',\n",
    "                         'RUEHMS/AMEMBASSY MUSCAT',\n",
    "                         'RUEHNR',\n",
    "                         'AMEMBASSY NAIROBI',\n",
    "                         'RUEHNE',\n",
    "                         'AMEMBASSY NEW DELHI',\n",
    "                         'RUEHNY',\n",
    "                         'AMEMBASSY OSLO',\n",
    "                         'RUEHOT',\n",
    "                         'AMEMBASSY OTTAWA',\n",
    "                         'RUEHZP',\n",
    "                         'AMEMBASSY PANAMA',\n",
    "                         'RUEHFR',\n",
    "                         'AMEMBASSY PARIS',\n",
    "                         'RUEHRH',\n",
    "                         'AMEMBASSY RIYADH',\n",
    "                         'RUEHRO',\n",
    "                         'RUEHYN',\n",
    "                         'RUEHGP/AMEMBASSY SINGAPORE',\n",
    "                         'RUEHSM',\n",
    "                         'AMEMBASSY STOCKHOLM',\n",
    "                         'RUEHTC',\n",
    "                         'RUEHKO/AMEMBASSY TOKYO',\n",
    "                         'RUCNDT/USMISSION',\n",
    "                         'EWWT',\n",
    "                         'PHSA',\n",
    "                         'PHUM PREL',\n",
    "                         'GM',\n",
    "                         'CGPCS',\n",
    "                         'ON PARTICIPATION ISSUE',\n",
    "                         'MFA UN Security Council Action',\n",
    "                         'the Contact Group for Piracy',\n",
    "                         'Turkish',\n",
    "                         'German',\n",
    "                         'the International Criminal Tribunal'],\n",
    "     'from': 'AMEMBASSY BERLIN',\n",
    "     'keywords': ['subject', 'expertise', 'stockhausen', '091715z', 'ruehul'],\n",
    "     'most_common_words': [('AMEMBASSY', 32),\n",
    "                           ('PRIORITY', 32),\n",
    "                           ('Germany', 5),\n",
    "                           ('national', 5),\n",
    "                           ('Stockhausen', 4),\n",
    "                           ('said', 4),\n",
    "                           ('cases', 4),\n",
    "                           ('region', 4),\n",
    "                           ('BERLIN', 3),\n",
    "                           ('CGPCS', 3),\n",
    "                           ('U.S.', 3),\n",
    "                           ('countries', 3),\n",
    "                           ('piracy', 3)],\n",
    "     'people_involved': ['RUEHBJ',\n",
    "                         '0210RUEHLO/',\n",
    "                         'SIPDIS ',\n",
    "                         'E.O.',\n",
    "                         'DECL',\n",
    "                         'STAN OTTO',\n",
    "                         'Dirk Stockhausen',\n",
    "                         'Koenig'],\n",
    "     'place_involved': ['BRUSSELS',\n",
    "                        'MOSCOW',\n",
    "                        'HAGUE',\n",
    "                        'NEW YORK',\n",
    "                        'BERLIN',\n",
    "                        'GERMANY',\n",
    "                        'U.S.',\n",
    "                        'SOMALIA',\n",
    "                        'NETHERLANDS',\n",
    "                        'KENYA',\n",
    "                        'CAMBODIA',\n",
    "                        'ARUSHA',\n",
    "                        'TANZANIA',\n",
    "                        'RWANDA'],\n",
    "     'place_of_document': 'BERLIN',\n",
    "     'subject': 'CGPCS: GERMANY AGREES ON PARTICIPATION ISSUE, BUT  IS STILL '\n",
    "                'OFFSIDE REGARDING INTERNATIONAL TRIBUNAL ',\n",
    "     'tags': ['EWWT', 'MARR', 'PGOV', 'PHSA', 'PHUM', 'PREL', 'MOPS', 'GM']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "\"Afghanistan\",\n",
    "\"Albania\",\n",
    "\"Algeria\",\n",
    "\"Andorra\",\n",
    "\"Angola\",\n",
    "\"Antigua and Barbuda\",\n",
    "\"Argentina\",\n",
    "\"Armenia\",\n",
    "\"Australia\",\n",
    "\"Austria\",\n",
    "\"Azerbaijan\",\n",
    "\"Bahamas\",\n",
    "\"Bahrain\",\n",
    "\"Bangladesh\",\n",
    "\"Barbados\",\n",
    "\"Belarus\",\n",
    "\"Belgium\",\n",
    "\"Belize\",\n",
    "\"Benin\",\n",
    "\"Bhutan\",\n",
    "\"Bolivia\",\n",
    "\"Bosnia and Herzegovina\",\n",
    "\"Botswana\",\n",
    "\"Brazil\",\n",
    "\"Brunei\",\n",
    "\"Bulgaria\",\n",
    "\"Burkina Faso\",\n",
    "\"Burundi\",\n",
    "\"Cambodia\",\n",
    "\"Cameroon\",\n",
    "\"Canada\",\n",
    "\"Cape Verde\",\n",
    "\"Central African Republic\",\n",
    "\"Chad\",\n",
    "\"Chile\",\n",
    "\"China\",\n",
    "\"Colombia\",\n",
    "\"Comoros\",\n",
    "\"Congo\",\n",
    "\"Cook Islands\",\n",
    "\"Costa Rica\",\n",
    "\"Cote d'Ivoire\",\n",
    "\"Croatia\",\n",
    "\"Cuba\",\n",
    "\"Cyprus\",\n",
    "\"Czech Republic\",\n",
    "\"Democratic Republic of Congo\",\n",
    "\"Denmark\",\n",
    "\"Djibouti\",\n",
    "\"Dominica\",\n",
    "\"Dominican Republic\",\n",
    "\"Ecuador\",\n",
    "\"Egypt\",\n",
    "\"El Salvador\",\n",
    "\"Equatorial Guinea\",\n",
    "\"Eritrea\",\n",
    "\"Estonia\",\n",
    "\"Ethiopia\",\n",
    "\"Fiji\",\n",
    "\"Finland\",\n",
    "\"France\",\n",
    "\"Gabon\",\n",
    "\"Gambia\",\n",
    "\"Georgia\",\n",
    "\"Germany\",\n",
    "\"Ghana\",\n",
    "\"Greece\",\n",
    "\"Grenada\",\n",
    "\"Guatemala\",\n",
    "\"Guinea\",\n",
    "\"Guinea-Bissau\",\n",
    "\"Guyana\",\n",
    "\"Haiti\",\n",
    "\"Honduras\",\n",
    "\"Hungary\",\n",
    "\"Iceland\",\n",
    "\"India\",\n",
    "\"Indonesia\",\n",
    "\"Iran\",\n",
    "\"Iraq\",\n",
    "\"Ireland\",\n",
    "\"Israel\",\n",
    "\"Italy\",\n",
    "\"Jamaica\",\n",
    "\"Japan\",\n",
    "\"Jordan\",\n",
    "\"Kazakhstan\",\n",
    "\"Kenya\",\n",
    "\"Kiribati\",\n",
    "\"Kuwait\",\n",
    "\"Kyrgyzstan\",\n",
    "\"Laos\",\n",
    "\"Latvia\",\n",
    "\"Lebanon\",\n",
    "\"Lesotho\",\n",
    "\"Liberia\",\n",
    "\"Libya\",\n",
    "\"Lithuania\",\n",
    "\"Luxembourg\",\n",
    "\"Macedonia\",\n",
    "\"Madagascar\",\n",
    "\"Malawi\",\n",
    "\"Malaysia\",\n",
    "\"Maldives\",\n",
    "\"Mali\",\n",
    "\"Malta\",\n",
    "\"Marshall Islands\",\n",
    "\"Mauritania\",\n",
    "\"Mauritius\",\n",
    "\"Mexico\",\n",
    "\"Micronesia (country)\",\n",
    "\"Moldova\",\n",
    "\"Mongolia\",\n",
    "\"Montenegro\",\n",
    "\"Morocco\",\n",
    "\"Mozambique\",\n",
    "\"Myanmar\",\n",
    "\"Namibia\",\n",
    "\"Nauru\",\n",
    "\"Nepal\",\n",
    "\"Netherlands\",\n",
    "\"New Zealand\",\n",
    "\"Nicaragua\",\n",
    "\"Niger\",\n",
    "\"Nigeria\",\n",
    "\"Niue\",\n",
    "\"North Korea\",\n",
    "\"Norway\",\n",
    "\"Oman\",\n",
    "\"Pakistan\",\n",
    "\"Palau\",\n",
    "\"Panama\",\n",
    "\"Papua New Guinea\",\n",
    "\"Paraguay\",\n",
    "\"Peru\",\n",
    "\"Philippines\",\n",
    "\"Poland\",\n",
    "\"Portugal\",\n",
    "\"Qatar\",\n",
    "\"Romania\",\n",
    "\"Russia\",\n",
    "\"Rwanda\",\n",
    "\"Saint Kitts and Nevis\",\n",
    "\"Saint Lucia\",\n",
    "\"Saint Vincent and the Grenadines\",\n",
    "\"Samoa\",\n",
    "\"Sao Tome and Principe\",\n",
    "\"Saudi Arabia\",\n",
    "\"Senegal\",\n",
    "\"Serbia\",\n",
    "\"Seychelles\",\n",
    "\"Sierra Leone\",\n",
    "\"Singapore\",\n",
    "\"Slovakia\",\n",
    "\"Slovenia\",\n",
    "\"Solomon Islands\",\n",
    "\"Somalia\",\n",
    "\"South Africa\",\n",
    "\"South Korea\",\n",
    "\"Spain\",\n",
    "\"Sri Lanka\",\n",
    "\"Sudan (former)\",\n",
    "\"Suriname\",\n",
    "\"Swaziland\",\n",
    "\"Sweden\",\n",
    "\"Switzerland\",\n",
    "\"Syria\",\n",
    "\"Tajikistan\",\n",
    "\"Tanzania\",\n",
    "\"Thailand\",\n",
    "\"Timor\",\n",
    "\"Togo\",\n",
    "\"Tonga\",\n",
    "\"Trinidad and Tobago\",\n",
    "\"Tunisia\",\n",
    "\"Turkey\",\n",
    "\"Turkmenistan\",\n",
    "\"Tuvalu\",\n",
    "\"Uganda\",\n",
    "\"Ukraine\",\n",
    "\"United Arab Emirates\",\n",
    "\"United Kingdom\",\n",
    "\"United States\",\n",
    "\"Uruguay\",\n",
    "\"Uzbekistan\",\n",
    "\"Vanuatu\",\n",
    "\"Venezuela\",\n",
    "\"Vietnam\",\n",
    "\"Yemen\",\n",
    "\"Zambia\",\n",
    "\"Zimbabwe\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_from(doc):\n",
    "    pos = doc['from'].index(' ') # attention avec WASHDC on a rien\n",
    "    place_from =  doc['from'][pos+1:]\n",
    "    return get_country(place_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country(document_city) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_countries(doc):\n",
    "    link = {} # ex: {'france': {'espagne':3, ...}, 'belgique': {'espagne':2, ...}, ...}\n",
    "    country_from = get_country_from(doc)\n",
    "    places_involved = doc['place_involved']\n",
    "    for place in place_involved:\n",
    "        if place in countries : # si la place est un pays (il faut bien transformer la place)\n",
    "            if place in link[country_from].keys(): # si le pays est déjà dans le lien\n",
    "                link[country_from][place] += 1\n",
    "            else : # si le pays n'est dans le lien\n",
    "                link[country_from][place] = 1 \n",
    "        else:\n",
    "            # si la place n'est pas un pays, on cherche le pays de la place\n",
    "            if place in place_to_country: # on vérifie si la place a déjà une correspondance à un pays dans le fichier\n",
    "                #blabla\n",
    "                country = place_to_country[place]\n",
    "                link[country_from][]\n",
    "            else:\n",
    "                country_of_place_involved = get_country(place)\n",
    "                # on ecrit la correspondance de la place dans un fichier\n",
    "                \n",
    "            # pour économiser des requetes, on stocke la correspondance des lieu pour voir si on a déjà fait la requête\n",
    "    link[country_from]\n",
    "    countries_to = get_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(place):\n",
    "    data = requests.get('https://nominatim.openstreetmap.org/search?q=\"{}\"&format=json&accept-language=en'.format(place))\n",
    "    data_json = data.json()\n",
    "    if len(data_json)>0:\n",
    "        place = data_json[0]['display_name']\n",
    "        country = place.split(\", \")[-1]\n",
    "        if country in countries: \n",
    "            return country\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1place : HONGKONG country : China\n",
      "2place : KOWLOON country : China\n",
      "2place : HONG KONG country : China\n",
      "2place : CHINA country : China\n",
      "2place : MASSACHUSETTS country : United States\n",
      "2place : UNITED STATES country : United States\n",
      "2place : SHENZHEN country : China\n",
      "1place : HOCHIMINHCITY country : Vietnam\n",
      "2place : CENTRAL HIGHLANDS country : Vietnam\n",
      "2place : HCMC country : United States\n",
      "2place : DAK LAK country : Vietnam\n",
      "2place : CAMBODIA country : Cambodia\n",
      "2place : VIETNAM country : Vietnam\n",
      "2place : WASHINGTON country : United States\n",
      "1place : JERUSALEM country : Israel\n",
      "2place : GAZA country : None\n",
      "2place : WEST BANK/GAZA COUNTRY country : United States\n",
      "2place : U.S. country : United States\n",
      "1place : BERLIN country : Germany\n",
      "2place : BRUSSELS country : Belgium\n",
      "2place : MOSCOW country : Russia\n",
      "2place : HAGUE country : Netherlands\n",
      "2place : NEW YORK country : United States\n",
      "2place : GERMANY country : Germany\n",
      "2place : SOMALIA country : Somalia\n",
      "2place : NETHERLANDS country : Netherlands\n",
      "2place : KENYA country : Kenya\n",
      "2place : ARUSHA country : Tanzania\n",
      "2place : TANZANIA country : Tanzania\n",
      "2place : RWANDA country : Rwanda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# il faut que les places soient nettoyés\n",
    "def write_place_country_correspondance(doc):\n",
    "    ## on read le fichier\n",
    "    with open('place_to_country_correspondance.txt') as json_file:\n",
    "        place_to_country_correspondance = json.load(json_file)\n",
    "        \n",
    "    place_from = doc['place_of_document']\n",
    "    places_involved = doc['place_involved']\n",
    "    if place_from not in place_to_country_correspondance.keys():\n",
    "        country = get_country(place_from)\n",
    "        place_to_country_correspondance[place_from] = country\n",
    "    for place in places_involved:\n",
    "        \n",
    "        if place not in countries and place not in place_to_country_correspondance.keys():\n",
    "            country = get_country(place)\n",
    "            place_to_country_correspondance[place] = country\n",
    "                \n",
    "    # on écrase le fichier\n",
    "    with open('place_to_country_correspondance.txt', 'w') as out_file:\n",
    "        json.dump(place_to_country_correspondance, out_file)\n",
    "\n",
    "for key in res.keys():\n",
    "    write_place_country_correspondance(res[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HONGKONG': 'China', 'HOCHIMINHCITY': 'United States', 'JERUSALEM': 'United States', 'BERLIN': 'Rwanda'}\n"
     ]
    }
   ],
   "source": [
    "f = open('place_to_country_correspondance.txt', 'r')\n",
    "content = json.load(f)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (py3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
